{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRN Normalization\n",
    "\n",
    "1.  Loading data into a gene expression matrix.\n",
    "2.  Munging data\n",
    "3.  MRN Normalization\n",
    "4.  Quick shot at maching learning.\n",
    "\n",
    "\"Trimmed Mean of M-values\" (TMM) normalization, published by [Robinson and Oshlack](https://www.frontiersin.org/articles/10.3389/fgene.2016.00164/full#B16) is a widely used method of normalizing gene expression in scRNA data.  A variant called MRN (Median Ratio Normalization) is described by [Maza et al.](https://www.tandfonline.com/doi/full/10.4161/cib.25849), and may perform slightly better than TMM.  We carry out MRN normalization on the P1902 scRNA data, and use the results in a quick machine learning application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import packages.  Put plots \"inline\" in the notebook.  \n",
    "\n",
    "import numpy as np  # For numerical computations.\n",
    "import pandas as pd  # Pandas for data analysis.\n",
    "import matplotlib.pyplot as plt  # For basic plotting.\n",
    "import seaborn as sns # For pretty visualization in Seaborn.  See https://seaborn.pydata.org/\n",
    "\n",
    "import os # Working with file directories, etc.\n",
    "\n",
    "from IPython.display import display # Pretty display of data frames.\n",
    "\n",
    "# Put plots inline rather than in a pop-up.\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning) #got annoyed of these red boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to section 2, if you have already loaded the data and have the pickles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.  Loading the data\n",
    "\n",
    "Start at section 2, if the raw data has already been processed and pickled.\n",
    "\n",
    "In this section, we load the gene expression data and some metadata.  The sequencing data is stored in a 'merged_gene_counts.txt'.  The metadata is stored in a separate file called 'meta_data_marty_inVitro_feb8.csv'.  We use the metadata to select bulk-cells from  experiment P9855.  The first function loads the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_meta(experiment, filename = 'meta_data_marty_inVitro_feb8.csv', report=True, bulks = False):\n",
    "    df = pd.read_csv(filename, sep=',',\n",
    "                     index_col=2, header=0, low_memory=False)\n",
    "    df = df[ df['Project_ID'] == experiment] # Only cells from the experiment.\n",
    "    if bulks:\n",
    "        df = df[ df['Number_Of_Cells'] >= 25] # Include only bulks.\n",
    "    else:\n",
    "        df = df[ df['Number_Of_Cells'] == 1] # Get rid of bulks.\n",
    "    if report:\n",
    "        if bulks:\n",
    "            print('{} bulks found in experiment {}'.format(len(df), experiment))\n",
    "        else:\n",
    "            print('{} single cells found in experiment {}'.format(len(df), experiment))\n",
    "        clones = df['Clone_ID'].unique()\n",
    "        print('{} Clones: {}'.format(len(clones), ', '.join(clones)))\n",
    "        print('The first five rows of the dataframe are below')\n",
    "        display(df[:5])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 single cells found in experiment P9855\n",
      "0 Clones: \n",
      "The first five rows of the dataframe are below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project_ID</th>\n",
       "      <th>Donor</th>\n",
       "      <th>Number_Of_Cells</th>\n",
       "      <th>Clone_ID</th>\n",
       "      <th>In_Vivo_Clone_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Project_ID, Donor, Number_Of_Cells, Clone_ID, In_Vivo_Clone_ID]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_df = get_meta('P9855', filename = 'meta_data_marty_inVitro_feb8.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 bulks found in experiment P9855\n",
      "53 Clones: P1_A03, P1_A05, P1_A12, P1_D09, P1_D12, P1_F10, P1_H01, P1_H10, P1_A08, P1_B10, P1_C11, P1_F02, P1_F04, P2_A04, P2_B11, P2_D12, P2_F01, P2_G01, P2_G09, P2_H01, P2_H04, P2_H05, P2_A05, P2_C12, P1_A03_ATAC_wellA1_rep1_1000, P1_A05_ATAC_wellA3_705, P1_D09_ATAC_wellA5_410, P1_F10_ATAC_wellA8_1000, P1_H01_ATAC_wellA9_rep1_1000, P1_H01_ATAC_wellA10_rep2_1000, P1_H10_ATAC_wellA11_rep1_1000, P1_A08_ATAC_wellB1_350, P1_A03_ATAC_wellA2_rep2_1000, P1_A12_ATAC_wellA4_506, P1_D12_ATAC_wellA6_1000, P1_H10_ATAC_wellA12_rep2_1000, P1_B10_ATAC_wellB2_269, P1_C11_wellB3_500, P1_F02_wellB4_500, P1_F04_wellB5_500, P2_A04_wellC1_1000_rep1, P2_A04_wellC2_1000_rep2, P2_B11_wellC3_700, P2_H05_wellC5_1000, P2_F01_wellC6_1000, P2_D12_wellC7_1000, P2_G01_wellC8_1000, P2_G09_wellC9_918, P2_H01_wellC10_1000, P2_H04_wellC11_1000_rep1, P2_H04_wellC12_1000_rep2, P2_H05_wellD1_1000, P2_A05_wellD2_1000\n",
      "The first five rows of the dataframe are below\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project_ID</th>\n",
       "      <th>Donor</th>\n",
       "      <th>Number_Of_Cells</th>\n",
       "      <th>Clone_ID</th>\n",
       "      <th>In_Vivo_Clone_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P9855_2001</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>P1_A03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2002</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>P1_A03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2003</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>P1_A03</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2004</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>P1_A05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2005</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>P1_A05</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Project_ID    Donor  Number_Of_Cells Clone_ID  In_Vivo_Clone_ID\n",
       "Sample_ID                                                                 \n",
       "P9855_2001      P9855  YFV2003               25   P1_A03               NaN\n",
       "P9855_2002      P9855  YFV2003               25   P1_A03               NaN\n",
       "P9855_2003      P9855  YFV2003               25   P1_A03               NaN\n",
       "P9855_2004      P9855  YFV2003               25   P1_A05               NaN\n",
       "P9855_2005      P9855  YFV2003               25   P1_A05               NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "meta_bulks = get_meta('P9855', filename = 'meta_data_marty_inVitro_feb8.csv', bulks=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project_ID</th>\n",
       "      <th>Donor</th>\n",
       "      <th>Number_Of_Cells</th>\n",
       "      <th>Clone_ID</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sample_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P9855_2001</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>A03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2002</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>A03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2003</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>A03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2004</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>A05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2005</th>\n",
       "      <td>P9855</td>\n",
       "      <td>YFV2003</td>\n",
       "      <td>25</td>\n",
       "      <td>A05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Project_ID    Donor  Number_Of_Cells Clone_ID\n",
       "Sample_ID                                               \n",
       "P9855_2001      P9855  YFV2003               25      A03\n",
       "P9855_2002      P9855  YFV2003               25      A03\n",
       "P9855_2003      P9855  YFV2003               25      A03\n",
       "P9855_2004      P9855  YFV2003               25      A05\n",
       "P9855_2005      P9855  YFV2003               25      A05"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_bulks.drop(meta_bulks.index[[range(69,99)]], inplace=True) # drop atac data... and c12 while we are cutting\n",
    "                                                                # the tail off of the dataframe \n",
    "meta_bulks.drop(['In_Vivo_Clone_ID'],axis=1, inplace=True)\n",
    "meta_bulks['Clone_ID'] = meta_bulks['Clone_ID'].str[-3:] # cleaning up clone id names\n",
    "meta_bulks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_bulks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['A03', 'A05', 'A12', 'D09', 'D12', 'F10', 'H01', 'H10', 'A08',\n",
       "       'B10', 'C11', 'F02', 'F04', 'A04', 'B11', 'F01', 'G01', 'G09',\n",
       "       'H04', 'H05'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_bulks['Clone_ID'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequencing data (in merged_gene_counts.txt) contains a separate row for each  gene.  The name of each column contains list of filenames (I'm guessing input for star), we will clean up column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_name</th>\n",
       "      <th>DDX11L1</th>\n",
       "      <th>WASH7P</th>\n",
       "      <th>MIR1302-10</th>\n",
       "      <th>FAM138A</th>\n",
       "      <th>OR4G4P</th>\n",
       "      <th>OR4G11P</th>\n",
       "      <th>OR4F5</th>\n",
       "      <th>RP11-34P13.7</th>\n",
       "      <th>RP11-34P13.8</th>\n",
       "      <th>CICP27</th>\n",
       "      <th>...</th>\n",
       "      <th>PPP1R12BP1</th>\n",
       "      <th>RNU6-1314P</th>\n",
       "      <th>CYCSP48</th>\n",
       "      <th>ANKRD36P1</th>\n",
       "      <th>TPTE2P4</th>\n",
       "      <th>CYCSP49</th>\n",
       "      <th>SLC25A15P1</th>\n",
       "      <th>PARP4P1</th>\n",
       "      <th>FAM58CP</th>\n",
       "      <th>CTBP2P1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>P9855_2019</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2054</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2072</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2025</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>P9855_2076</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 63677 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_name   DDX11L1  WASH7P  MIR1302-10  FAM138A  OR4G4P  OR4G11P  OR4F5  \\\n",
       "P9855_2019        0       0           0        0       0        0      0   \n",
       "P9855_2054        0       0           0        0       0        0      0   \n",
       "P9855_2072        0       0           0        0       0        0      0   \n",
       "P9855_2025        0       0           0        0       0        0      0   \n",
       "P9855_2076        0       0           0        0       0        0      0   \n",
       "\n",
       "gene_name   RP11-34P13.7  RP11-34P13.8  CICP27  ...  PPP1R12BP1  RNU6-1314P  \\\n",
       "P9855_2019             0             0       0  ...           0           0   \n",
       "P9855_2054             0             0       0  ...           0           0   \n",
       "P9855_2072             0             0       0  ...           0           0   \n",
       "P9855_2025             0             0       0  ...           0           0   \n",
       "P9855_2076             0             0       0  ...           0           0   \n",
       "\n",
       "gene_name   CYCSP48  ANKRD36P1  TPTE2P4  CYCSP49  SLC25A15P1  PARP4P1  \\\n",
       "P9855_2019        0          0        0        0           0        0   \n",
       "P9855_2054        0          0        0        0           0        0   \n",
       "P9855_2072        0          0        0        0           0        0   \n",
       "P9855_2025        0          0        0        0           0        0   \n",
       "P9855_2076        0          0        0        0           0        0   \n",
       "\n",
       "gene_name   FAM58CP  CTBP2P1  \n",
       "P9855_2019        0        0  \n",
       "P9855_2054        0        0  \n",
       "P9855_2072        0        0  \n",
       "P9855_2025        0        0  \n",
       "P9855_2076        0        0  \n",
       "\n",
       "[5 rows x 63677 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_merged_genes = pd.read_csv('merged_gene_counts.txt', sep='\\t', index_col=1)\n",
    "read_merged_genes.columns = read_merged_genes.columns.str[:10] # 10 characters in P9855_20**\n",
    "read_merged_genes.drop(['Geneid'],axis=1, inplace=True)\n",
    "read_merged_genes = read_merged_genes.transpose() # tanspose dataframe for later analysis infrastructure\n",
    "#read_merged_genes.index.names = ['Sample_ID']\n",
    "read_merged_genes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_merged_genes.to_pickle('P9855_rawreads.pkl') # Save file as a pickle.\n",
    "meta_bulks.to_pickle('P9855_meta.pkl') # Pickle the metadata too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function loads an entire *list* of cells, and places their gene expression data into the rows of a matrix.  The rows are indexed by the cell names, and the columns by genes.  The data is the gene expression, as raw number of reads.  This may take a little while, so we give progress updates every 10 cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.  Munging data\n",
    "\n",
    "Start here if you have the pickles!  We filter the data a bit, before normalization downstream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulks_raw = pd.read_pickle('P9855_rawreads.pkl') # Load bulks expression matrix from a pickle.\n",
    "meta_df = pd.read_pickle('P9855_meta.pkl') # Load metadata from a pickle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes = list(bulks_raw.columns)  # The names of the genes. \n",
    "bulks = list(bulks_raw.index) # The names of the bulks.\n",
    "clones = sorted(list(meta_bulks.Clone_ID.unique())) # The names of the clones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing TCRs and rarely-expressed genes\n",
    "\n",
    "T cells have special genetically rearranged receptors called TCRs.  These are made of segments called TRBV9, TRBJ2-4, TRAV12-2, TRAJ14, etc.  Bascally any gene that is called these letters followed by a number -- TRBV, TRBJ, TRAV, TRAJ -- is part of this receptor and they are defined as being clonal.  Therefore we exclude these genes since we want to find more interesting similarities within clonal populations.\n",
    "\n",
    "The following loads a list of genes to be excluded from the data for later analysis.  The excluded genes should be given in a csv file with *one* column.  No row labels should be given.  The first row should be a descriptive header, like \"Genes to exclude.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_filename = 'TRgenes.csv'  # CHANGE this if needed.  I added TRAC and TRDV3 as requested.\n",
    "exc_df = pd.read_csv(exc_filename, sep=',', header=0)\n",
    "exclude_genes = exc_df.iloc[:,0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_relevant(gf, eg, prevalence=0.1, threshold = 10): # gf = expression matrix, eg = list of genes to exclude\n",
    "    '''\n",
    "    Outputs True if the gene is relevant for analysis.  We throw out excluded genes.\n",
    "    By default, we take genes that are found in at least 5% of all cells at a level of\n",
    "    10 counts or more.\n",
    "    '''\n",
    "    nonzero_count = (gf > threshold).sum(axis=0)\n",
    "    nonzero_proportion = nonzero_count / len(gf)\n",
    "    return [gene for gene in gf.columns if\n",
    "           (gene not in eg) & \n",
    "           (nonzero_proportion[gene] > prevalence)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-aa900bfc2eec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mgenes_relevant\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_relevant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbulks_raw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexclude_genes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-ffb3758ab3f1>\u001b[0m in \u001b[0;36mget_relevant\u001b[0;34m(gf, eg, prevalence, threshold)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mnonzero_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnonzero_proportion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnonzero_count\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     return [gene for gene in gf.columns if\n\u001b[0m\u001b[1;32m     10\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0mgene\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m            (nonzero_proportion[gene] > prevalence)]\n",
      "\u001b[0;32m<ipython-input-14-ffb3758ab3f1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m     return [gene for gene in gf.columns if\n\u001b[1;32m     10\u001b[0m            \u001b[0;34m(\u001b[0m\u001b[0mgene\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m&\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m            (nonzero_proportion[gene] > prevalence)]\n\u001b[0m",
      "\u001b[0;32m/anaconda3/envs/diana_env/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1476\u001b[0m         raise ValueError(\"The truth value of a {0} is ambiguous. \"\n\u001b[1;32m   1477\u001b[0m                          \u001b[0;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1478\u001b[0;31m                          .format(self.__class__.__name__))\n\u001b[0m\u001b[1;32m   1479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1480\u001b[0m     \u001b[0m__bool__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "\n",
    "genes_relevant = get_relevant(bulks_raw, exclude_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print(\"{} cells are measured, from {} to {}.\".format(len(cells), cells[0], cells[-1]))\n",
    "print(\"{} bulks are measured, from {} to {}.\".format(len(bulks), bulks[0], bulks[-1]))\n",
    "print(\"{} genes are measured, from {} to {}.\".format(len(genes),genes[0],genes[-1]))\n",
    "genes_excluded = [gene for gene in exclude_genes if gene in genes]\n",
    "print(\"{} TCR genes were excluded, from {} to {}.\".format(len(genes_excluded), genes_excluded[0], genes_excluded[-1]))\n",
    "print(\"{} genes are considered relevant, from {} to {}.\".format(len(genes_relevant), genes_relevant[0], genes_relevant[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing poor quality libraries and overexpressing cells\n",
    "\n",
    "Next we remove poor quality libraries -- by removing cells which express too few genes.  We also remove cells that may be dividing, and thus express too many genes.  To visualize this, we produce \"violin-plots\" giving the number of genes expressed by each cell, sorted by clonality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nGene(ge, md, cutoff = 10, plot=True): # ge = gene expression, md = meta data\n",
    "    nG = ge.apply(lambda row: sum(row > cutoff), axis=1) # Number of genes expressed.\n",
    "    nG.name = 'num_genes'\n",
    "    clonalities = md.Clone_ID\n",
    "    nGene_df = pd.concat([nG, clonalities], axis=1)\n",
    "    if plot:\n",
    "        fig,ax = plt.subplots(figsize=(12,8))\n",
    "        sns.violinplot(x=\"Clone_ID\", y=\"num_genes\", inner='quartiles', data=nGene_df, ax=ax)\n",
    "        sns.swarmplot(x=\"Clone_ID\", y=\"num_genes\", color=\"white\", size=3, data=nGene_df, ax=ax);\n",
    "    return nGene_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nG = nGene(bulks_raw, meta_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pick out the \"good cells\", whose expressed-gene-number is within two standard deviations of the mean (within each clone)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nG_std = nG.groupby('Clone_ID').apply(np.std)\n",
    "nG_means = nG.groupby('Clone_ID').apply(np.mean)\n",
    "nG_lowcut = (nG_means - 2*nG_std).num_genes\n",
    "nG_highcut = (nG_means + 2*nG_std).num_genes\n",
    "cells_good = [c for c in cells if \n",
    "              (nG.num_genes[c] >= nG_lowcut[nG.Clone_ID[c]]) and \n",
    "              (nG.num_genes[c] <= nG_highcut[nG.Clone_ID[c]]) \n",
    "             ]\n",
    "print('{} cells remaining after {} poor libraries removed.'.format(len(cells_good), len(cells) - len(cells_good)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nG = nGene(bulks_raw.loc[cells_good], meta_df.loc[cells_good]) # Post-trimming violin-plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  3.  MRN Normalization.\n",
    "\n",
    "Here we implement MRN Normalization on the gene expression data, closely following the convenient outline in Section 3.2 of [Maza](https://www.frontiersin.org/articles/10.3389/fgene.2016.00164/full).  We begin by putting our filtered data into a dataframe.  The dataframe `EM` (for \"expression matrix\") contains the gene expressions for the cells, filtered as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "EM = bulks_raw#[genes_relevant]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EM.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step I:  Prenormalization by library size.\n",
    "\n",
    "In Maza's article, $X_{gkr}$ stands for the raw count (number of reads) of gene $g$, for a cell number $r$ among clone $k$.  This information is contained in our expression matrix `EM`.  The first step is to normalize by library size, dividing $X_{gkr}$ by the total number of reads $N_{kr}$ of cell with numbers $k$, $r$.  \n",
    "\n",
    "We find the total number of reads for each cell by simply summing the numbers in each row of the data frame `EM`.  We don't need to worry about the separate indices $k$ and $r$ yet.  We examine the resulting \"library size\" below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "library_size = EM.sum(axis=1) # Drop the clone column.  Sum along rows.\n",
    "print(library_size.head())\n",
    "library_size.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The library size is about 1.6 million +/- 440,000.  Now we normalize the expression matrix by dividing every cell's raw counts by the cell's library size.  Note that `EM` is a dataframe whose rows are indexed by the cells.  `library_size` is a series (basically an array) whose rows are indexed by cells.  Numpy/pandas will divide one array by another, term by term, if they have the same size.  So it can divide *each column* of `EM` by `library size`, in a quickly-broadcasted division.  To perform this on every column, we use the `apply` method with a \"lambda\" function... it's the quickest method I know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = EM.apply(lambda column : column / library_size)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y.sort_index().iloc[28:31, 68:78] #just looking for some nonzero values in the df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now `Y` is the dataframe with counts normalized by library size, and we pass to the next step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step II:  Creation of reference sample.\n",
    "\n",
    "A difference between TMM (used in edgeR), RLE (used in DeSeq2), and MRN, is how they create a reference sample.  In MRN, a reference sample is created by averaging the previous dataframe `Y` over cells within a single condition (clone).  We carry this out here.\n",
    "\n",
    "Note the method-chaining in defining `Y_clonal` below.  The `assign` method tacks on a new column to `Y` for the clone_IDs.  The `groupby` method then groups cells by clonotypes.  The `apply` method then takes the means within each clonotype.  The end result is to replace the (prenormalized) gene expression for *each cell* by the averages for each clonotype.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_clonal = Y.assign(Clone=meta_df['Clone_ID']).groupby('Clone').apply(np.mean) # Takes a few seconds.\n",
    "display(Y_clonal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take our reference sample to be the A7 clonal average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_ref = Y_clonal.loc['D12'] # Our reference sample.  Basically an average of all cells of clonotype D12.\n",
    "Y_ref.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step III:  Computation of size relative to reference sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we compute relative scaling factors for each clone, based on the median fold-changes between gene expression within that clone and the reference clone (A7, we have chosen above).  Due to dropouts (values of 0 in gene expression), we discard genes with zeros when computing fold changes.  This avoids division-by-zero problems, and it matches the implementation of [Maza et al.](https://www.tandfonline.com/doi/full/10.4161/cib.25849).  (See the R code in the supplementary information).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tau = pd.Series(index = clones)\n",
    "for clone in clones: # Why not a little loop.\n",
    "    numerator = Y_clonal.loc[clone]\n",
    "    denominator = Y_ref\n",
    "    ok_genes = [gene for gene in genes_relevant if (numerator[gene] != 0) and (denominator[gene] != 0)]\n",
    "    ratios = numerator[ok_genes] / denominator[ok_genes] # The ratios.\n",
    "    tau[clone] = np.median(ratios)\n",
    "print(tau)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step IV:  Adjustment of relative scaling factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step does not occur in MRN normalization.  Yay!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step V:  Effective library size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# intermediate series to match the clone IDs with the samples\n",
    "clonalities = pd.Series(meta_df['Clone_ID'], index=library_size.index)\n",
    "clonalities.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#intermediate series to map tau scaling values to the samples\n",
    "scalar_lib_size = clonalities.map(tau)\n",
    "scalar_lib_size.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#final series, for this step at least as the library_size values are scaled by tau values\n",
    "effective_lib_size = scalar_lib_size * library_size\n",
    "effective_lib_size.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step VI:  Computation of relative normalization/size factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_mean = np.exp(effective_lib_size.apply(np.log).mean()) # The geometric mean of the effective_lib_size series.\n",
    "geo_mean # A single number!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "effective_lib_size.mean() # Compare the geometric mean (above) to the usual mean here.  They shouldn't be *too* far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_normalization_factor = effective_lib_size / geo_mean\n",
    "relative_normalization_factor.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step VII:  Normalization of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we normalize our raw counts by the relative normalization factor we just\n",
    "# calculated in Step VI\n",
    "mrn_counts = EM.div(relative_normalization_factor, axis=0)\n",
    "mrn_counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.  Quick shot at machine learning\n",
    "\n",
    "After preprocessing the data, one might want to quickly check how well gene expression can predict clonotype.  The following steps will test out a linear support vector classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "# Import various functions for stats.\n",
    "from scipy.stats import f_oneway, binom, binom_test, kruskal, norm # For p-values, kruskal-wallis, Gaussian\n",
    "from scipy.stats import kurtosis, skew # For detecting bimodality\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "from bisect import bisect # See bisect.bisect.\n",
    "from itertools import compress # I don't recall why this is here.\n",
    "\n",
    "# Import from scikit, for machine learning.\n",
    "# from sklearn import mixture  # Import Gaussian mixture\n",
    "\n",
    "from sklearn.preprocessing import Binarizer, MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit, train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.svm import LinearSVC # Linear Support Vector Classifier \n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    " \n",
    "from sklearn.cluster import MiniBatchKMeans, KMeans\n",
    "from sklearn.metrics.pairwise import pairwise_distances_argmin\n",
    "\n",
    "from sklearn.manifold import TSNE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mrn_counts\n",
    "X_cells = mrn_counts.index\n",
    "y = meta_df.loc[X_cells].Clone_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SVMpipe = make_pipeline(MinMaxScaler(), \n",
    "                        SelectKBest(score_func = f_classif, k=100), \n",
    "                        LinearSVC(random_state=0, tol=1e-4, max_iter = 2000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DANGER DANGER:  The following suppresses all warnings from Python.\n",
    "# Otherwise, you'll probably get a bunch of convergence warnings...\n",
    "# Alternatively, increase the number of iterations in the SVM.\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ignore warnings.\n",
    "\n",
    "param_grid = dict(linearsvc__C=[0.001, 0.01, 0.1, 1.0, 10, 100],\n",
    "                  selectkbest__k = range(50,251,25),\n",
    "                 )\n",
    "\n",
    "grid_search = GridSearchCV(SVMpipe, param_grid=param_grid, cv=5, iid=False) #5-fold cross-validation.\n",
    "grid_search.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CV_map(gs, swap=False):  # parameter_grid and grid_search.\n",
    "    '''\n",
    "    A general-purpose visualization for grid-search cross-validations.\n",
    "    Displays predictive accuracy as a heatmap, based on different\n",
    "    choices of parameters.  Displays optimal parameters in title.\n",
    "    \n",
    "    Args:\n",
    "        gs (sklearn.model_selection.GridSearchCV):  The grid-search object.\n",
    "        swap:  Set to True to switch the axes.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "        \n",
    "    '''\n",
    "    results = gs.cv_results_\n",
    "    means = results['mean_test_score']\n",
    "    params = list(gs.param_grid.keys())\n",
    "    \n",
    "    ser = pd.Series(list(means),\n",
    "                  index=pd.MultiIndex.from_tuples(\n",
    "                      [tuple(d.values()) for d in results['params']])\n",
    "               )\n",
    "    gs_df = ser.unstack().fillna(0)\n",
    "    gs_df.shape \n",
    "    if swap:\n",
    "        gs_df = gs_df.transpose()\n",
    "        params = params[::-1] # Switch the order of the parameter list.\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(12,12))\n",
    "    sns.heatmap(gs_df, annot=True, square=True, fmt=\"2.0%\", linewidths=.5, \n",
    "                cbar_kws={'fraction':0.025, 'pad':0.05}, ax=ax)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([.5, .6, .7, .8, .9])\n",
    "    cbar.set_ticklabels(['50%', '60%', '70%', '80%', '90%'])\n",
    "    ax.set_xlabel(params[1])\n",
    "    ax.set_ylabel(params[0])\n",
    "    plt.yticks(rotation=0)\n",
    "    bestacc = gs.best_score_\n",
    "    ax.set_title(\"Result of grid-search with 5-fold cross-validation. \\n\"\n",
    "                 \"Best score {0:2.1%} with parameters \\n\"\n",
    "                 \"{1} \".format(gs.best_score_, gs.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV_map(grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "\n",
    "def confusion_matrix(X,y,pipe, reps=2, classlist = None):\n",
    "    if classlist:\n",
    "        classes = classlist\n",
    "    else:\n",
    "        classes = sorted(y.unique())\n",
    "    counts = pd.DataFrame(0, index=classes, columns=classes)\n",
    "    cpops = pd.DataFrame(0, index=classes, columns=['pop'])\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for t in range(reps):\n",
    "        this_pipe = base.clone(pipe)\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "        this_pipe.fit(X_train, y_train)\n",
    "        y_pred = this_pipe.predict(X_test)\n",
    "        actual = y_test\n",
    "        predicted = y_pred\n",
    "        for j in range(len(y_test)):\n",
    "            total += 1\n",
    "            if y_test[j] == y_pred[j]:\n",
    "                correct += 1\n",
    "            cpops.loc[y_test[j],'pop'] += 1\n",
    "            counts.loc[y_test[j], y_pred[j]] += 1\n",
    "    \n",
    "    valid = counts.apply(lambda column : column/cpops['pop']) #['pop'] )\n",
    "    \n",
    "    f, ax = plt.subplots(figsize=(len(classes)+1,len(classes)))\n",
    "    sns.heatmap(valid, annot=valid, square=True, fmt=\"2.0%\", linewidths=.5, \n",
    "                cbar_kws={'fraction':0.046, 'pad':0.04}, ax=ax)\n",
    "    cbar = ax.collections[0].colorbar\n",
    "    cbar.set_ticks([0, .25, .5, .75, 1])\n",
    "    cbar.set_ticklabels(['0%', '25%', '50%', '75%', '100%'])\n",
    "    ax.set_ylabel(\"Actual class\")\n",
    "    ax.set_xlabel(\"Predicted class\")\n",
    "    ax.set_title(\"Overall prediction accuracy {:0.3%}. \\n\"\n",
    "                 \"{} trials, in {} batches with independent splits.\".format(correct/total, total, reps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_k = grid_search.best_params_['selectkbest__k'] # Use optimal number of genes.\n",
    "opt_C = grid_search.best_params_['linearsvc__C'] # Use optimal C-parameter for linear SVM.\n",
    "\n",
    "SVMpipe = make_pipeline(MinMaxScaler(), \n",
    "                        SelectKBest(score_func = f_classif, k=opt_k), \n",
    "                        LinearSVC(random_state=0, tol=1e-4, max_iter = 2000, C=opt_C))\n",
    "\n",
    "confusion_matrix(X,y,SVMpipe, reps=50, classlist = clones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
